<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta http-equiv="X-UA-Compatible" content="IE=edge">

<title>  Robostats Wiki | Perceptron & SVM</title>
<meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design.
">

<!-- Open Graph -->


<!-- Bootstrap & MDB -->
<link href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css" rel="stylesheet" integrity="sha512-MoRNloxbStBcD8z3M/2BmnT+rg4IsMxPkXaGh2zD6LGNNFE80W3onsAhRcMAMrSoyWL9xD7Ert0men7vR8LUZg==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/css/mdb.min.css" integrity="sha512-RO38pBRxYH3SoOprtPTD86JFOclM51/XTIdEPh5j8sj4tp8jmQIx26twG52UaLi//hQldfrh7e51WzP9wuP32Q==" crossorigin="anonymous" />

<!-- Fonts & Icons -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css"  integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.0/css/academicons.min.css" integrity="sha512-W4yqoT1+8NLkinBLBZko+dFB2ZbHsYLDdr50VElllRcNt2Q4/GSs6u71UHKxB7S6JEMCp5Ve4xjh3eGQl/HRvg==" crossorigin="anonymous">
<link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

<!-- Code Syntax Highlighting -->
<link rel="stylesheet" href="https://gitcdn.link/repo/jwarby/jekyll-pygments-themes/master/github.css" />

<!-- Styles -->
<link rel="shortcut icon" href="/robostats-wiki/assets/img/favicon.ico">
<link rel="stylesheet" href="/robostats-wiki/assets/css/main.css">

<link rel="canonical" href="/robostats-wiki/blog/2020/perceptron-svm/">

<!-- Theming-->




    
<!-- MathJax -->
<script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.1.2/es5/tex-mml-chtml.js"></script>
<script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>


    <script src="/robostats-wiki/assets/js/distillpub/template.v2.js"></script>
    <script src="/robostats-wiki/assets/js/distillpub/transforms.v2.js"></script>
    
  </head>

  <d-front-matter>
    <script async type="text/json">{
      "title": "Perceptron & SVM",
      "description": "instructions to add a blog post on this website",
      "published": "2020-12-21 00:00:00 -0500",
      "authors": [
        
        {
          "author": "Szuyu Lin",
          "authorURL": "",
          "affiliations": [
            {
              "name": "Robotics Institute, Carnegie Mellon University",
              "url": ""
            }
          ]
        }
        
      ],
      "katex": {
        "delimiters": [
          {
            "left": "$",
            "right": "$",
            "display": false
          },
          {
            "left": "$$",
            "right": "$$",
            "display": true
          }
        ]
      }
    }</script>
  </d-front-matter>

  <body class="fixed-top-nav sticky-bottom-footer">

    <!-- Header -->

    <header>

    <!-- Nav Bar -->
    <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
    <div class="container">
      
      <a class="navbar-brand title font-weight-lighter" href="/robostats-wiki/">
       <span class="font-weight-bold"></span>   Robostats Wiki
      </a>
      
      <!-- Navbar Toogle -->
      <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar top-bar"></span>
        <span class="icon-bar middle-bar"></span>
        <span class="icon-bar bottom-bar"></span>
      </button>
      <div class="collapse navbar-collapse text-right" id="navbarNav">
        <ul class="navbar-nav ml-auto flex-nowrap">
          <!-- About -->
          <li class="nav-item ">
            <a class="nav-link" href="/robostats-wiki/">
              about
              
            </a>
          </li>
          
          <!-- Blog -->
          <li class="nav-item active">
            <a class="nav-link" href="/robostats-wiki/blog/">
              blog
              
            </a>
          </li>
          
          <!-- Other pages -->
          
          
          
          
          
          
          
          
          
          
          
        </ul>
      </div>
    </div>
  </nav>

</header>


    <!-- Content -->

    <div class="post distill">

      <d-title>
        <h1>Perceptron & SVM</h1>
        <p>instructions to add a blog post on this website</p>
      </d-title>

      <d-byline></d-byline>

      <d-article>
        <h2 id="perceptron">Perceptron</h2>
<p>The Perceptron can be viewed as a single-layer neural network. It is an online binary classification algorithm, which modifies its decision boundary after receiving each training instance.</p>

<h3 id="perceptions-decision-rule">Perception’s decision rule</h3>
<p>For each input or training instance received, perception uses its decision rule to compute the dot product of the input $\vec{x}$ and current weights $\vec{w}$, then output the $sign (+/-)$ of the dot product.</p>

\[\hat{y}^{(t)} = sign(w^{(t-1)} \cdot x^{(t)})\]

<h3 id="perceptions-update-rule">Perception’s update rule</h3>
<p>In the online learning process, the perceptron then receives the true label of the training instance.</p>

<p>If the predicted sign is identical to the training instance, nothing happens. On the other hand, if the perceptron makes a mistake, the weights are updated with the update rule.</p>

\[w^{(t)} = w^{(t-1)} + y^{(t)} \cdot x^{(t)} \cdot 1[y^{(t)} \neq \hat{y}^{(t)}]\]

<h3 id="upper-bound">Upper Bound</h3>
<p>If the data is linearly separable, the perceptron algorithm is guaranteed to make a finite number of mistakes.</p>

<p>To compute the mistake bound of perceptron, we define the “Potential Function” as following (the L2 norm of the weight vector):</p>

\[\Phi^{(t)} = \|{w^{(t)}}\|^2 = \sum(w_n^{(t)})^2\]

<p>If our learner makes a mistake at timestep $t$, the potential function becomes the following:</p>

\[\Phi^{(t)} = \left\Vert{w^{(t-1)} + y^{(t)}x^{(t)}} \right\Vert ^
 =\left\Vert{w^{(t)}}\right\Vert ^2 + \left\Vert x \right\Vert ^2 + 2y^{(t)} \langle w^{(t-1)}, x^{(t)} \rangle\]

<p>How do we determine the sign of the $2y^{(t)} \langle w^{(t-1)}, x^{(t)} \rangle $ term, when the learner makes a mistake?</p>

<p>According to the decision rule, if the learner made a mistake, the prediction $\hat{y}^{(t)} = \langle w^{(t-1)}, x^{(t)} \rangle$ must have the opposite sign of the label $y^{(t)}$,</p>

<p>the $2y^{(t)} \langle w^{(t-1)}, x^{(t)} \rangle $ term is negative, therefore the following inequality holds:</p>

\[\Phi^{(t)} \leq \left\Vert {w^{(t-1)}} \right\Vert ^2 + \left\Vert x^{(t)} \right\Vert ^2\]

<p>Let $R=\max_{t}| x^{(t)}| $ be the norm of input vector $x$, we can upper bound the potential function:</p>

\[\Phi^{(t)} \leq \left\Vert {w^{(t-1)}} \right\Vert ^2 + R^2\]

<p>On the other hand, it our learner does not make a mistake at timestep $t$, the update rule becomes the following:</p>

\[w^{(t)} = w^{(t-1)}\]

<p>And the potential function becomes:</p>

\[\Phi^{(t)}=\left\Vert {w^{(t)}} \right\Vert ^2 = \left\Vert {w^{(t-1)}} \right\Vert ^2\]

<p>Combining both cases, our upper bound is:</p>

\[\Phi^{(t)} \leq \left\Vert {w^{(t-1)}} \right\Vert ^2 + R^2\]

<p>Starting from the base case, where $M^{(t)}$ is the total mistakes made at timestep $t$:</p>

\[\Phi^{(1)} \leq \left\Vert w^{(0)} \right\Vert ^2 + M^{(1)}R^2\]

<p>And the upper bound of the potential function after $T$ timesteps:</p>

\[\Phi^{(T)} \leq \left\Vert w^{(0)} \right\Vert ^2 + M^{(T)}R^2\]

<p>If we initialize $\left\Vert w^{(0)} \right\Vert $ to zero, we get:</p>

\[\Phi^{(T)} \leq M^{(T)}R^2\]

<h3 id="lower-bound">Lower Bound</h3>

<p>We assume the data to be linear separable here. Let $w^\star$ be the perfect classifier, and it is a unit vector, i.e. $\left\Vert w^\star \right\Vert = 1$ (assume exists).</p>

<p>The dot product $\langle w^\star, w^{(t-1)} \rangle$ will be the target we will derive the bounds for.</p>

\[\langle w^\star, w^{(t-1)} \rangle = \left\Vert w^\star \right\Vert \cdot \left\Vert w^{(T)} \right\Vert cos(\theta) \leq \left\Vert w^{(T)} \right\Vert\]

<p>$cos(\theta) \leq 1$, so the upper bound on the dot product is: $\langle w^\star, w^{(t-1)} \rangle \leq \left\Vert w^{(T)} \right\Vert$.</p>

<p>For the lower bound derivation, we recall the update rule:</p>

\[w^{(t)} = w^{(t-1)} + y^{(t)} \cdot x^{(t)} \cdot 1[y^{(t)} \neq \hat{y}^{(t)}]\]

\[\langle w^\star, w^{(t)} \rangle = \langle w^\star, w^{(t-1)} \rangle + y^{(t)} \langle w^\star, x^{(t)} \rangle \cdot 1[y^{(t)} \neq \hat{y}^{(t)}]\]

<p>Since our $w^\star$ is a perfect classifier, the sign of $y^{(t)} \langle w^\star, x^{(t)} \rangle$ is guaranteed positive.</p>

<p>Now define the margin $\gamma = \min_{t} y_t \langle w^\star, x^{(t)} \rangle \geq 0$, we have the base case:</p>

\[\langle w^\star, w^{(1)} \rangle \geq \langle w^\star, w^{(0)} \rangle + \gamma \cdot M^{(1)}\]

\[\langle w^\star, w^{(T)} \rangle \geq \langle w^\star, w^{(0)} \rangle + \gamma \cdot M^{(T)}\]

<p>Initialize $w^{(0)} = 0$, we have the lower bound $ \langle w^\star, w^{(T)} \rangle \geq \gamma \cdot M^{(T)}$</p>

<h3 id="combining-both-bounds">Combining both bounds</h3>

\[\left\Vert w^{(t)} \right\Vert \geq \gamma \cdot M^{(T)}\]

<p>Recall potential: $ \Phi^{(T)} = \left\Vert w^{(T)} \right\Vert ^2 $</p>

<p>We have the lower bound $ \Phi^{(T)} = \left\Vert w^{(T)} \right\Vert ^2 \geq (\gamma \cdot M^{(T)})^2, \Phi^{(T)} \geq (\gamma \cdot M^{(T)})^2 $</p>

<p>Combining with the upper bound $\Phi^{(T)} \leq M^{(T)} \cdot R^2 $, we have the mistake bound of perceptron:</p>

\[M^{(T)} \leq \frac{R^2}{\gamma^2}\]

<h3 id="the-margin">The margin</h3>

<p>The margin is the distance between the decision boundary and the closest data point.</p>

\[\gamma = min_{t} y^{(t)} \langle w^\star, x^{(t)} \rangle &gt; 0\]

<p>The margin represents the degree of the separability of the data. If the margin is small, the data is harder to separate, therefore the learner makes more mistakes before finding the correct decition boundary.</p>

<p>For the norm $ R = max_{t} \left\Vert x^{(t)} \right\Vert $, if we have a large $R$, we will also have a larger mistake bound, and make more mistakes before finding the correct decision boundary.</p>

<h3 id="incremental-update-svm">Incremental update SVM</h3>

<p>Formula of a line: $w \cdot x + b = 0$, where $w, b$ are the weight and bias respectively.</p>

<p>Distance between line $w \cdot x + b = 0$ and origin: $\frac{b}{\left\Vert w \right\Vert}$</p>

<p>Distance between two parallel lines $w \cdot x + b = 0$ and $w \cdot x + (b+1) = 0$: $\frac{1}{\left\Vert w \right\Vert}$</p>

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        <img class="img-fluid rounded z-depth-1" src="/robostats-wiki/assets/img/dist.jpg" />
    </div>
</div>

<h2 id="support-vector-machine">Support Vector Machine</h2>

<p>The best decision boundary is the one that maximizes the margin (i.e. distance to closest points), which is the most robust to purturbations in the inputs.</p>

<p>Solution for the best decision boundary:</p>

<p>for $y_{i}=+1, wx+b \geq \gamma$</p>

<p>for $y_{i}=-1, wx+b \leq -\gamma$</p>

<p>The margin here is $\frac{\gamma}{\left\Vert w \right\Vert}$, which is the distance between the decision boundary and the closest points to it, should be maximized.</p>

<p>The points on the lines $wx + b = \pm \gamma$ are called “support vectors”.</p>

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        <img class="img-fluid rounded z-depth-1" src="/robostats-wiki/assets/img/svm.jpg" />
    </div>
</div>

<h3 id="objective-function">Objective function</h3>

<p>The object function of maximizing the margin is:
\(max_{\gamma, w, b} \frac{\gamma}{\left\Vert w \right\Vert} \: s.t. wx_i+b \begin{cases} \geq \gamma, &amp; y_i=+1 \\ \leq \gamma, &amp; y_i=-1\end{cases} \, \forall i\)</p>

<p>If we set $\gamma = 1$, we can rewrite the objective and constraints:
\(max_{w, b} \frac{1}{\left\Vert w \right\Vert} \: s.t. y_i(wx_i + b) \geq 1 \, \forall i\)</p>

<p>which is equivalent to:
\(min_{w, b} \left\Vert w \right\Vert ^2 \: s.t. y_i(wx_i + b) \geq 1 \, \forall i\)</p>

<p>This is a convex quadratic programming (QP) problem, for which a unique solution exists.</p>

<h3 id="soft-margin">Soft margin</h3>

<p>“Slack variables” make soft margin SVMs different from standard hard margin SVMs.</p>

<p>Slack variables allow trade off between the margin and the object function, i.e. whether to linearly separate all data but have a very narrow margin, or maximize the margin allowing a few mistakes.</p>

<p>To include slack variables, we modify the previous constraint: $ min_{w, b} \left\Vert w \right\Vert ^2 s.t. y_i(wx_i + b) \geq 1 \, \forall i $</p>

\[min_{w, \zeta} \left\Vert w \right\Vert ^2 \: s.t. y_i(wx_i + b) \geq 1 - \zeta_i, \zeta_i \geq 0 \, \forall i\]

<p>But if we have large $\zeta$’s, a large degree of mistakes would be allowed, though we might have a small objective but the SVM will learn nothing and have mistakes everywhere. Therefore we need a “regularization” term to prevent large $\zeta$’s.</p>

\[min_{w, \zeta} \left\Vert w \right\Vert ^2 + C \sum_i \zeta_i \: s.t. y_i(wx_i + b) \geq 1 - \zeta_i, \zeta_i \geq 0 \, \forall i\]

<p>A large regularization term $C$ allows few mistakes and will produce a small margin. A small $C$, on the other hand, allows more mistakes and will result in a large margin.</p>

<h2 id="sgd-for-linear-svms">SGD for linear SVMs</h2>

<p>Objective: \(min_{w, \zeta} \left\Vert w \right\Vert ^2 + C \sum_i \zeta_i \: s.t. y_i(wx_i + b) \geq 1 - \zeta_i, \zeta_i \geq 0 \, \forall i\)</p>

<p>When we don’t make a mistake, $y_i(wx_i + b) \geq 1$ holds, no need of slack, $\zeta_i=0$</p>

<p>When we make a mistake, $y_i(wx_i + b) &lt; 1, \; \zeta_i = 1 - y_i(wx_i + b)$</p>

<p>Summarizing both cases we have: $\zeta_i = max(0, 1-y_i(wx_i + b)) $</p>

<p>And our new objective:</p>

\[min_{w, \zeta} \left\Vert w \right\Vert ^2 + C \sum_i max(0, 1-y_i(wx_i + b)) \: s.t. y_i(wx_i + b) \geq 1 - \zeta_i, \zeta_i \geq 0 \, \forall i\]

<h3 id="hinge-loss-and-subgradients">Hinge loss and subgradients</h3>

<p>$y_i(wx_i + b) = y_i \cdot \hat{y}_i$</p>

<p>Hinge loss $l_{hinge} = max(0, 1 - y_i \cdot \hat{y}_i)$</p>

<p>Soft SVM can be framed as a regularization convex loss optimization problem, so we can solve it with SGD!</p>

<p>SGD requires the gradient to be differentiable, however, the hinge loss is convex but not differentiable everywhere, therefore we have to take advantage of subgradients.</p>

<p>Use subgradients to optimize objective $min_{w} \left\Vert w \right\Vert ^2 + C \sum_i max(0, 1-y_m(w^T x_m))$:</p>

<p>Subgradient of the objective:</p>

\[v = \begin{cases}
0 &amp; y_m(w^T x_m) \geq 1 \\
-y_m x_m &amp; y_m(w^T x_m) &lt; 1
\end{cases}\]

<p>$v = -y_m x_m 1[y_m(w^T x_m) &lt; 1]$</p>


      </d-article>

      <d-appendix>
        <d-footnote-list></d-footnote-list>
        <d-citation-list></d-citation-list>
      </d-appendix>

    </div>

    <!-- Footer -->

    
<footer class="sticky-bottom mt-5">
  <div class="container">
    &copy; Copyright 2020   Robostats Wiki.
    
    
    Last updated: December 22, 2020.
    
  </div>
</footer>



  </body>

  <d-bibliography src="/robostats-wiki/assets/bibliography/2018-12-22-distill.bib">
  </d-bibliography>

</html>
